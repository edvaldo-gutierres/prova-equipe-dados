# Prova de ProficiÃªncia - Engenheiro de Dados | CantuStore

## ğŸ“‹ DescriÃ§Ã£o

Este repositÃ³rio contÃ©m a soluÃ§Ã£o desenvolvida para o teste de proficiÃªncia da vaga de **Engenheiro de Dados** da **CantuStore**. O projeto demonstra habilidades tÃ©cnicas em SQL, anÃ¡lise de dados e processamento de dados utilizando a plataforma **Databricks** para resolver problemas reais de e-commerce.

## ğŸ¢ Sobre a CantuStore

A **CantuStore** Ã© uma plataforma de tecnologia e logÃ­stica que viabiliza soluÃ§Ãµes completas em pneus, guiando quem compra e apoiando quem vende. Produtos e serviÃ§os em uma experiÃªncia 360Â° para abrir caminhos e ver pessoas e negÃ³cios evoluindo junto com a gente.

## ğŸ¯ Objetivos do Teste

### Parte 1 - SQL (Databricks SQL)
- Demonstrar proficiÃªncia em consultas SQL complexas no ambiente Databricks
- Resolver problemas de classificaÃ§Ã£o e hierarquia organizacional
- Implementar anÃ¡lises de comissÃµes e vendas usando Databricks SQL

### Parte 2 - AnÃ¡lise de Dados (Databricks Notebooks)
- Analisar dados de carrinho abandonado em e-commerce usando PySpark
- Identificar padrÃµes e insights para reduÃ§Ã£o de abandono
- Gerar relatÃ³rios estratÃ©gicos para tomada de decisÃ£o
- Utilizar Databricks e PySpark para processamento distribuÃ­do

## ğŸ› ï¸ Tecnologias Utilizadas

- **Databricks** - Plataforma principal de desenvolvimento
- **Databricks SQL** - Consultas SQL e anÃ¡lise de dados
- **PySpark** - Framework para big data e processamento distribuÃ­do
- **Databricks Notebooks** - Desenvolvimento e documentaÃ§Ã£o
- **Delta Lake** - Armazenamento de dados otimizado
- **Git** - Controle de versÃ£o
- **Markdown** - DocumentaÃ§Ã£o

## ğŸ“ Estrutura do Projeto

```
prova-equipe-dados/
â”œâ”€â”€ README.md                    # DocumentaÃ§Ã£o principal
â”œâ”€â”€ LICENSE                      # LicenÃ§a MIT
â”œâ”€â”€ .gitignore                   # Arquivos ignorados pelo Git
â”œâ”€â”€ databricks/                  # CÃ³digo Databricks
â”‚   â”œâ”€â”€ sql/                     # Queries SQL
â”‚   â”‚   â”œâ”€â”€ 1.1_campeonato.sql  # Consulta de classificaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ 1.2_comissoes.sql   # AnÃ¡lise de comissÃµes
â”‚   â”‚   â””â”€â”€ 1.3_hierarquia.sql  # OrganizaÃ§Ã£o empresarial
â”‚   â””â”€â”€ notebooks/               # Databricks Notebooks
â”‚       â”œâ”€â”€ 2.1_analise_carrinho_abandonado.py
â”‚       â”œâ”€â”€ 2.2_relatorios.py
â”‚       â””â”€â”€ 2.3_exportacao_dados.py
â”œâ”€â”€ data/                        # Dados de entrada
â”‚   â””â”€â”€ carrinho_abandonado.csv
â”œâ”€â”€ reports/                     # RelatÃ³rios gerados
â”‚   â”œâ”€â”€ relatorio_produtos_mensal.csv
â”‚   â”œâ”€â”€ relatorio_diario.csv
â”‚   â””â”€â”€ top_50_carrinhos.txt
â””â”€â”€ requirements.txt             # DependÃªncias Python
```

## ğŸš€ Como Executar

### PrÃ©-requisitos

- **Databricks Workspace** - Acesso Ã  plataforma Databricks
- **Databricks Runtime** - Cluster configurado com PySpark
- **Databricks SQL** - Acesso ao SQL Warehouse
- **Git** - Controle de versÃ£o

### ConfiguraÃ§Ã£o no Databricks

1. **Clone o repositÃ³rio**:
```bash
git clone https://github.com/edvaldo-gutierres/prova-equipe-dados.git
```

2. **Configure o Databricks CLI**:
```bash
pip install databricks-cli
databricks configure --token
```

3. **Importe os notebooks**:
```bash
databricks workspace import_dir databricks/notebooks /Shared/Prova-Equipe-Dados
```

4. **Configure o cluster**:
   - Runtime: Databricks Runtime 13.3 LTS (Scala 2.12, Spark 3.4.1)
   - Node Type: Standard_DS3_v2 ou superior
   - Min Workers: 1, Max Workers: 3

5. **Configure o SQL Warehouse**:
   - Size: Small (2X-Small)
   - Auto-stop: 10 minutos
   - Auto-scaling: Enabled

## ğŸ“Š Desafios Implementados

### Parte 1 - SQL (Databricks SQL)

#### 1.1 Campeonato
- **Objetivo**: Calcular pontos de equipes em campeonato
- **Regras**: VitÃ³ria = 3 pontos, Empate = 1 ponto, Derrota = 0 pontos
- **Entrada**: Tabelas `times` e `jogos`
- **SaÃ­da**: ClassificaÃ§Ã£o ordenada por pontos
- **Tecnologia**: Databricks SQL

#### 1.2 ComissÃµes
- **Objetivo**: Identificar vendedores com atÃ© 3 transferÃªncias totalizando â‰¥ R$ 1.024
- **Entrada**: Tabela `comissoes`
- **SaÃ­da**: Lista de vendedores que atendem aos critÃ©rios
- **Tecnologia**: Databricks SQL

#### 1.3 OrganizaÃ§Ã£o Empresarial
- **Objetivo**: Encontrar chefes indiretos com salÃ¡rio â‰¥ 2x do funcionÃ¡rio
- **Entrada**: Tabela `colaboradores`
- **SaÃ­da**: Relacionamento funcionÃ¡rio-chefe hierÃ¡rquico
- **Tecnologia**: Databricks SQL

### Parte 2 - AnÃ¡lise de Dados (Databricks Notebooks)

#### 2.1 AnÃ¡lise de Carrinho Abandonado
- **Produtos com mais abandono** - AnÃ¡lise PySpark
- **Duplas de produtos abandonados** - Processamento distribuÃ­do
- **Produtos com aumento de abandono** - AnÃ¡lise temporal
- **Produtos novos no primeiro mÃªs** - AgregaÃ§Ãµes complexas
- **Estados com mais abandonos** - AnÃ¡lise geogrÃ¡fica

#### 2.2 RelatÃ³rios EstratÃ©gicos
- **RelatÃ³rio mensal**: Produtos, carrinhos abandonados, itens, valor nÃ£o faturado
- **RelatÃ³rio diÃ¡rio**: Quantidade de carrinhos, itens, valor nÃ£o faturado
- **ExportaÃ§Ã£o**: Delta Lake e CSV

#### 2.3 ExportaÃ§Ã£o de Dados
- **Arquivo .txt**: Top 50 carrinhos com maior valor total
- **Layout especÃ­fico**: Dados estruturados conforme especificaÃ§Ã£o
- **Processamento**: PySpark para performance

## ğŸ”§ Desenvolvimento

### PadrÃµes de CÃ³digo

- **Databricks SQL**: OtimizaÃ§Ã£o de queries para performance
- **PySpark**: Uso eficiente de DataFrames e Spark SQL
- **Notebooks**: DocumentaÃ§Ã£o clara com markdown
- **Delta Lake**: UtilizaÃ§Ã£o de recursos ACID
- **Commits**: AtÃ´micos e descritivos

### Estrutura de Commits

```
feat: adiciona consulta SQL para campeonato no Databricks
fix: corrige cÃ¡lculo de pontos com PySpark
docs: atualiza documentaÃ§Ã£o dos notebooks
refactor: otimiza query de hierarquia com Delta Lake
test: adiciona testes para anÃ¡lise de dados
```

## ğŸ“ˆ MÃ©tricas de Sucesso

- [ ] Consultas SQL executando no Databricks SQL
- [ ] AnÃ¡lises PySpark gerando insights relevantes
- [ ] RelatÃ³rios exportados no formato correto
- [ ] Performance otimizada com processamento distribuÃ­do
- [ ] DocumentaÃ§Ã£o clara nos notebooks
- [ ] Uso eficiente dos recursos Databricks

## ğŸ“ DocumentaÃ§Ã£o

- **README.md** - DocumentaÃ§Ã£o principal do projeto
- **Databricks SQL/*** - ComentÃ¡rios nas consultas SQL
- **Databricks Notebooks/*** - AnÃ¡lises documentadas com markdown
- **LICENSE** - LicenÃ§a MIT para uso livre

## ğŸ¤ ContribuiÃ§Ã£o

Este Ã© um projeto de teste de proficiÃªncia. Para contribuiÃ§Ãµes em projetos futuros:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/NovaAnalise`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona anÃ¡lise de tendÃªncias'`)
4. Push para a branch (`git push origin feature/NovaAnalise`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ‘¨â€ğŸ’» Autor

**Edvaldo Gutierres**

- LinkedIn: [https://www.linkedin.com/in/edvaldo-gutierres-6b4a5768/]
- Email: [edvaldo_gutierres@yahoo.com.br]
- GitHub: [https://github.com/edvaldo-gutierres]

---