# ğŸ“„ Prova de ProficiÃªncia â€“ Engenheiro de Dados | CantuStore

OlÃ¡, Capitani! Espero que estejam todos bem.

Me chamo **Edvaldo Gutierres** â€” [LinkedIn](https://www.linkedin.com/in/edvaldo-gutierres-6b4a5768/)

---

## ğŸ“‹ DescriÃ§Ã£o

Este repositÃ³rio apresenta a soluÃ§Ã£o desenvolvida para a **prova tÃ©cnica da vaga de Engenheiro de Dados** da **CantuStore**. O projeto evidencia competÃªncias tÃ©cnicas em **SQL**, **PySpark**, **anÃ¡lise de dados** e **boas prÃ¡ticas de engenharia de dados** na plataforma **Databricks**, com foco em problemas reais do contexto de e-commerce.

> Embora a execuÃ§Ã£o prÃ¡tica nÃ£o tenha sido solicitada, optei por validar todos os scripts SQL tanto no ambiente **Databricks SQL** quanto via **dbt**, antecipando um dos requisitos desejÃ¡veis da vaga e reforÃ§ando a aderÃªncia ao cenÃ¡rio de produÃ§Ã£o.

---

## ğŸ¢ Sobre a CantuStore

A **CantuStore** Ã© uma plataforma de tecnologia e logÃ­stica especializada em soluÃ§Ãµes completas para o mercado de pneus. Com uma abordagem 360Â°, conecta quem compra e quem vende, promovendo a evoluÃ§Ã£o conjunta de pessoas e negÃ³cios.

---

## ğŸ¯ Objetivos do Teste

### Parte 1 â€“ SQL (Databricks SQL)

* Demonstrar domÃ­nio em **consultas SQL** avanÃ§adas
* Resolver desafios de **classificaÃ§Ã£o**, **hierarquia** e **anÃ¡lise de comissÃµes**
* Explorar recursos do Databricks SQL para consultas performÃ¡ticas

### Parte 2 â€“ AnÃ¡lise de Dados (Databricks Notebooks)

* Investigar padrÃµes de **abandono de carrinho** com **PySpark**
* Gerar **insights e relatÃ³rios estratÃ©gicos**
* Utilizar o Delta Lake para **armazenamento otimizado**
* Automatizar exportaÃ§Ãµes de dados estruturados

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Databricks** â€“ Plataforma principal de desenvolvimento
* **Databricks SQL** â€“ Consultas e anÃ¡lises analÃ­ticas
* **PySpark** â€“ Processamento distribuÃ­do e transformaÃ§Ãµes de dados
* **Delta Lake** â€“ Armazenamento com suporte ACID e time travel
* **dbt (Data Build Tool)** â€“ Modelagem declarativa, seeds, versionamento e modularizaÃ§Ã£o
* **Poetry** â€“ Gerenciamento de dependÃªncias e ambientes virtuais
* **Git** â€“ Controle de versÃ£o
* **Markdown** â€“ DocumentaÃ§Ã£o clara e estruturada

---

## ğŸ“ Estrutura inicial do Projeto

```
prova-equipe-dados/
â”œâ”€â”€ ğŸ“„ README.md                 # DocumentaÃ§Ã£o principal do projeto
â”œâ”€â”€ ğŸ“‹ LICENSE                   # LicenÃ§a MIT
â”œâ”€â”€ ğŸš« .gitignore               # Arquivos ignorados pelo controle de versÃ£o
â”œâ”€â”€ ğŸ“¦ pyproject.toml           # ConfiguraÃ§Ã£o Poetry e dependÃªncias
â”œâ”€â”€ ğŸ”’ poetry.lock              # Lock file com versÃµes fixas
â”‚
â”œâ”€â”€ ğŸ—ï¸ databricks/              # Scripts e notebooks Databricks
â”‚   â”œâ”€â”€ sql/                    # Consultas SQL (Parte 1)
â”‚   â”‚   â”œâ”€â”€ 1.1_campeonato.sql     # â†’ ClassificaÃ§Ã£o de times
â”‚   â”‚   â”œâ”€â”€ 1.2_comissoes.sql      # â†’ AnÃ¡lise de vendedores
â”‚   â”‚   â””â”€â”€ 1.3_hierarquia.sql     # â†’ Estrutura organizacional
â”‚   â”‚
â”‚   â””â”€â”€ notebooks/              # AnÃ¡lises PySpark (Parte 2)
â”‚       â”œâ”€â”€ 2.1_analise_carrinho_abandonado.py  # â†’ PadrÃµes de abandono
â”‚       â”œâ”€â”€ 2.2_relatorios.py                   # â†’ RelatÃ³rios estratÃ©gicos
â”‚       â””â”€â”€ 2.3_exportacao_dados.py             # â†’ ExportaÃ§Ã£o estruturada
â”‚
â”œâ”€â”€ ğŸ”§ dbt_project/             # Projeto dbt para validaÃ§Ã£o e modelagem
â”‚   â”œâ”€â”€ dbt_project.yml            # â†’ ConfiguraÃ§Ã£o do projeto dbt
â”‚   â”œâ”€â”€ profiles.yml               # â†’ Perfis de conexÃ£o Databricks
â”‚   â”œâ”€â”€ models/                    # â†’ Modelos SQL modulares
â”‚   â”‚   â”œâ”€â”€ staging/               # â†’ Camada de staging
â”‚   â”‚   â”œâ”€â”€ marts/                 # â†’ Modelos finais (classificacao, comissoes, hierarquia)
â”‚   â”‚   â””â”€â”€ schema.yml             # â†’ DocumentaÃ§Ã£o e testes
â”‚   â”œâ”€â”€ seeds/                     # â†’ Dados estÃ¡ticos (CSV)
â”‚   â”‚   â””â”€â”€ sample_data.csv        # â†’ Dados de teste para validaÃ§Ã£o
â”‚   â”œâ”€â”€ tests/                     # â†’ Testes automatizados
â”‚   â””â”€â”€ macros/                    # â†’ FunÃ§Ãµes reutilizÃ¡veis
â”‚
â”œâ”€â”€ ğŸ“Š data/                    # Datasets de entrada
â”‚   â””â”€â”€ carrinho_abandonado.csv    # â†’ Base principal para anÃ¡lises
â”‚
â””â”€â”€ ğŸ“ˆ reports/                 # RelatÃ³rios e exportaÃ§Ãµes geradas
    â”œâ”€â”€ relatorio_produtos_mensal.csv  # â†’ Resumo mensal
    â”œâ”€â”€ relatorio_diario.csv           # â†’ MÃ©tricas diÃ¡rias
    â””â”€â”€ top_50_carrinhos.txt           # â†’ Maiores carrinhos (formato .txt)
```
---

## ğŸš€ Como Executar

### PrÃ©-requisitos

* **Databricks Workspace** com permissÃµes
* **SQL Warehouse** e **cluster PySpark**
* **Poetry** instalado (`pip install poetry`)
* **Git** instalado

### Etapas

```bash
# Clone o repositÃ³rio
git clone https://github.com/edvaldo-gutierres/prova-equipe-dados.git
cd prova-equipe-dados

# Instale dependÃªncias com Poetry
poetry install
poetry add databricks-cli dbt-databricks --group dev

# Ative o ambiente virtual
poetry shell

# Configure o Databricks CLI
databricks configure --token

# Importe os notebooks para o workspace
databricks workspace import_dir databricks/notebooks /Shared/Prova-Equipe-Dados

# Execute validaÃ§Ãµes dbt (opcional)
cd dbt_project
dbt seed    # Carrega dados de teste
dbt run     # Executa modelos
dbt test    # Valida testes automatizados
```

**ConfiguraÃ§Ãµes sugeridas:**

* **Cluster:** Databricks Runtime 13.3 LTS (Spark 3.4.1)
* **SQL Warehouse:** Size Small, auto-stop em 10 min

### Gerenciamento de DependÃªncias

O projeto utiliza **Poetry** para:
* ğŸ“¦ **Gerenciamento de dependÃªncias** â€“ Controle preciso de versÃµes
* ğŸ”’ **Ambientes isolados** â€“ Evita conflitos entre projetos
* ğŸš€ **Build e deploy** â€“ Empacotamento simplificado
* ğŸ“‹ **Metadata do projeto** â€“ ConfiguraÃ§Ã£o centralizada no `pyproject.toml`

---

## ğŸ“Š Desafios Implementados

### Parte 1 â€“ SQL

#### 1.1 Campeonato

* CÃ¡lculo de pontuaÃ§Ã£o por time (vitÃ³ria, empate, derrota)
* ClassificaÃ§Ã£o final com ordenaÃ§Ã£o por pontos

#### 1.2 ComissÃµes

* Filtragem de vendedores com atÃ© 3 transferÃªncias â‰¥ R\$1.024
* AnÃ¡lise agrupada por vendedor

#### 1.3 Hierarquia Organizacional

* Mapeamento de chefes diretos e indiretos
* VerificaÃ§Ã£o de salÃ¡rio â‰¥ 2x o subordinado

### Parte 2 â€“ PySpark

#### 2.1 AnÃ¡lise de Carrinhos Abandonados

* Produtos com maior Ã­ndice de abandono
* PadrÃµes de abandono em duplas de produtos
* Comparativo temporal e por estado

#### 2.2 RelatÃ³rios EstratÃ©gicos

* RelatÃ³rios mensais e diÃ¡rios exportados em CSV
* MÃ©tricas: quantidade de itens, valor total, produtos

#### 2.3 ExportaÃ§Ã£o Estruturada

* GeraÃ§Ã£o de `.txt` com os 50 maiores carrinhos abandonados
* Layout com formataÃ§Ã£o especÃ­fica via PySpark

---

## ğŸ”§ Desenvolvimento

### PadrÃµes de CÃ³digo e Boas PrÃ¡ticas

* **Databricks SQL** â€“ Escrita otimizada com foco em performance e clareza
* **PySpark** â€“ Processamento distribuÃ­do com DataFrames e expressÃµes eficientes
* **dbt** â€“ Modelos modulares com uso de `seeds`, `ref`, testes e versionamento
* **Poetry** â€“ Dependency management, versionamento semÃ¢ntico e builds reproduzÃ­veis
* **Notebooks** â€“ DocumentaÃ§Ã£o com markdowns, visualizaÃ§Ãµes e organizaÃ§Ã£o por etapas
* **Delta Lake** â€“ Uso de ACID, controle de SCDs e time travel
* **Git** â€“ Commits atÃ´micos e semÃ¢nticos

### Exemplo de Commits

```
feat: adiciona cÃ¡lculo de classificaÃ§Ã£o no campeonato
fix: ajusta condiÃ§Ã£o de empate em anÃ¡lise de comissÃµes
refactor: organiza lÃ³gica de hierarquia com auto join
build: atualiza dependÃªncias Poetry para dbt 1.6.0
docs: atualiza README com orientaÃ§Ãµes de execuÃ§Ã£o
test: valida queries dbt com dados de seed
```

---

## ğŸ“ˆ Indicadores de Sucesso

* âœ… ExecuÃ§Ã£o validada no Databricks SQL e dbt
* âœ… RelatÃ³rios exportados corretamente
* âœ… Processamento escalÃ¡vel com PySpark
* âœ… Scripts claros e bem documentados
* âœ… Dados versionados e modularizados com dbt
* âœ… Testes e evidÃªncias alinhadas ao cenÃ¡rio real

---

## ğŸ‘¨â€ğŸ’» Sobre o Autor

**Edvaldo Gutierres**

* ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/edvaldo-gutierres-6b4a5768/)
* ğŸ“§ [edvaldo\_gutierres@yahoo.com.br](mailto:edvaldo_gutierres@yahoo.com.br)
* ğŸ’» [GitHub](https://github.com/edvaldo-gutierres)

---

## ğŸ™ Agradecimentos

AgradeÃ§o a oportunidade e estou Ã  disposiÃ§Ã£o para qualquer esclarecimento ou conversa tÃ©cnica.

---
